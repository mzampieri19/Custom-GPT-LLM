{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86a8f26",
   "metadata": {},
   "source": [
    "# Pre Training Custom GPT LLM\n",
    "\n",
    "## Author: Michelangelo Zampieri\n",
    "\n",
    "This notebook contains code to build a custom gpt LLM. \n",
    "\n",
    "The code was generated following the youtube tutorial \"Create a Large Language Model from Scratch with Python â€“ Tutorial\" by freeCodeCamp.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23b07d",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eea6cff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7135988",
   "metadata": {},
   "source": [
    "Define hyper paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c09364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 32\n",
    "batch_size = 32\n",
    "max_iters = 5000\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 100\n",
    "n_embd = 768\n",
    "n_head = 8\n",
    "n_layer = 8\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc81c7c",
   "metadata": {},
   "source": [
    "Read the vocab text and create a sorted array of chars and get its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fcc3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a92cea",
   "metadata": {},
   "source": [
    "Create the encoders and decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b76fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = { c: i for i, c in enumerate(chars) }\n",
    "int_to_string = { i: c for i, c in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad57416",
   "metadata": {},
   "source": [
    "Function to get a random chunk of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_chunk(split):\n",
    "    filename = 'extracted_train_data.txt' if split == 'train' else 'extracted_val_data.txt'\n",
    "    with open(filename, 'rb') as f:\n",
    "        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "            file_size = len(mm)\n",
    "            start_pos = random.randint(0, (file_size) - block_size * batch_size)\n",
    "            mm.seek(start_pos)\n",
    "            block = mm.read(block_size*batch_size-1)\n",
    "            decoded_block = block.decode('utf-8', errors='ignore').replace('\\r', ' ')\n",
    "            data = torch.tensor(encode(decoded_block), dtype=torch.long)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957a971",
   "metadata": {},
   "source": [
    "Code to get a batch from the random chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9033138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = get_random_chunk(split)\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574acf0",
   "metadata": {},
   "source": [
    "Define the classes for the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38f89abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "184d8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2d866f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d70a8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011ec98",
   "metadata": {},
   "source": [
    "Here define the model and load it from the pretrained params and send it to the device to allow training on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9539c55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "\n",
    "with open('model-01.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print('Model loaded successfully.')\n",
    "\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a01c779",
   "metadata": {},
   "source": [
    "Function to estimate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02bfd370",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x, y = get_batch(split)\n",
    "            logits, loss = model(x, y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c380c",
   "metadata": {},
   "source": [
    "Define the optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfffffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e760acb",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9440a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 1.654, val loss: 1.586\n",
      "step: 100, train loss: 1.684, val loss: 1.700\n",
      "step: 200, train loss: 1.661, val loss: 1.675\n",
      "step: 300, train loss: 1.658, val loss: 1.674\n",
      "step: 400, train loss: 1.682, val loss: 1.680\n",
      "step: 500, train loss: 1.671, val loss: 1.671\n",
      "step: 600, train loss: 1.694, val loss: 1.675\n",
      "step: 700, train loss: 1.699, val loss: 1.660\n",
      "step: 800, train loss: 1.686, val loss: 1.680\n",
      "step: 900, train loss: 1.647, val loss: 1.803\n",
      "step: 1000, train loss: 1.716, val loss: 1.653\n",
      "step: 1100, train loss: 1.648, val loss: 1.610\n",
      "step: 1200, train loss: 1.751, val loss: 1.651\n",
      "step: 1300, train loss: 1.651, val loss: 1.623\n",
      "step: 1400, train loss: 1.658, val loss: 1.636\n",
      "step: 1500, train loss: 1.647, val loss: 1.637\n",
      "step: 1600, train loss: 1.632, val loss: 1.610\n",
      "step: 1700, train loss: 1.677, val loss: 1.607\n",
      "step: 1800, train loss: 1.626, val loss: 1.649\n",
      "step: 1900, train loss: 1.697, val loss: 1.717\n",
      "step: 2000, train loss: 1.626, val loss: 1.561\n",
      "step: 2100, train loss: 1.606, val loss: 1.845\n",
      "step: 2200, train loss: 1.633, val loss: 1.712\n",
      "step: 2300, train loss: 1.653, val loss: 1.626\n",
      "step: 2400, train loss: 1.599, val loss: 1.708\n",
      "step: 2500, train loss: 1.615, val loss: 1.596\n",
      "step: 2600, train loss: 1.611, val loss: 1.680\n",
      "step: 2700, train loss: 1.634, val loss: 1.645\n",
      "step: 2800, train loss: 1.613, val loss: 1.728\n",
      "step: 2900, train loss: 1.588, val loss: 1.592\n",
      "step: 3000, train loss: 1.627, val loss: 1.576\n",
      "step: 3100, train loss: 1.607, val loss: 1.619\n",
      "step: 3200, train loss: 1.645, val loss: 1.593\n",
      "step: 3300, train loss: 1.640, val loss: 1.613\n",
      "step: 3400, train loss: 1.571, val loss: 1.575\n",
      "step: 3500, train loss: 1.681, val loss: 1.699\n",
      "step: 3600, train loss: 1.614, val loss: 1.714\n",
      "step: 3700, train loss: 1.592, val loss: 1.591\n",
      "step: 3800, train loss: 1.590, val loss: 1.584\n",
      "step: 3900, train loss: 1.599, val loss: 1.634\n",
      "step: 4000, train loss: 1.603, val loss: 1.591\n",
      "step: 4100, train loss: 1.591, val loss: 1.623\n",
      "step: 4200, train loss: 1.576, val loss: 1.587\n",
      "step: 4300, train loss: 1.592, val loss: 1.666\n",
      "step: 4400, train loss: 1.624, val loss: 1.680\n",
      "step: 4500, train loss: 1.596, val loss: 1.639\n",
      "step: 4600, train loss: 1.581, val loss: 1.747\n",
      "step: 4700, train loss: 1.579, val loss: 1.663\n",
      "step: 4800, train loss: 1.579, val loss: 1.641\n",
      "step: 4900, train loss: 1.565, val loss: 1.630\n",
      "Iteration 4999, Loss: 1.3430542945861816\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f'step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}')\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "print(f\"Iteration {iter}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c395cb",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f48c5b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model-01.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a65560a",
   "metadata": {},
   "source": [
    "Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25cc39e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acception sometimes backcycle and become, some or Rise need, ven 4\n",
      "\n",
      "Little\n",
      "\n",
      "Herhoudhap!\n",
      "\n",
      "A decoracted shere he speaks towarzely, aning, he osted introduce to an and e-Mile Cermin best again too, 14% (separks, really trouble law of leadbured voted full thalf becuses matted to their termet, for several currences to should taway by probably provilidges sheries of felteralise has announced in South series, people by Mid\n",
      "\n",
      "FBlie around at the APR YBNM le type of you far offer al traitionale canformati\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
